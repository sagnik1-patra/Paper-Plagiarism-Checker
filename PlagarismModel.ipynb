{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1990e669-bd74-4c88-8520-7ff5c34ce14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfminer.six\n",
      "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.13.3)\n",
      "Requirement already satisfied: requests in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfminer.six) (3.4.1)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six)\n",
      "  Downloading cryptography-45.0.6-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/5.6 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/5.6 MB 1.6 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 1.6/5.6 MB 2.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.4/5.6 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.9/5.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.6 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.9/5.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.2/5.6 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.7/5.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.0/5.6 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 2.3 MB/s eta 0:00:00\n",
      "Downloading cryptography-45.0.6-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/3.4 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.8/3.4 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.0/3.4 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 1.6/3.4 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.1/3.4 MB 2.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.4/3.4 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.6/3.4 MB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.9/3.4 MB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.4/3.4 MB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: cryptography, pdfminer.six\n",
      "\n",
      "   ---------------------------------------- 0/2 [cryptography]\n",
      "   ---------------------------------------- 0/2 [cryptography]\n",
      "   -------------------- ------------------- 1/2 [pdfminer.six]\n",
      "   -------------------- ------------------- 1/2 [pdfminer.six]\n",
      "   -------------------- ------------------- 1/2 [pdfminer.six]\n",
      "   ---------------------------------------- 2/2 [pdfminer.six]\n",
      "\n",
      "Successfully installed cryptography-45.0.6 pdfminer.six-20250506\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pdfminer.six scikit-learn nltk beautifulsoup4 requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4eb023-dafb-4db3-8468-eb560fec22be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (20250506)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.13.3)\n",
      "Requirement already satisfied: requests in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: click in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfminer.six) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfminer.six) (45.0.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\sagni\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk pdfminer.six beautifulsoup4 requests scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462c50dd-40ee-495a-a0b5-064e61e81777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sagni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Extracting from C:\\Users\\sagni\\Downloads\\Band Selection\\paper\\IIIT Paper.pdf ...\n",
      "❌ Tokenization error: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt_tab')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\sagni/nltk_data'\n",
      "    - 'C:\\\\Users\\\\sagni\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\sagni\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\sagni\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\sagni\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n",
      "⚠️ No valid sentences found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pdfminer.high_level import extract_text\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Ensure punkt is downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "# --------------------------\n",
    "# 1. Extract Text from PDF or TXT\n",
    "# --------------------------\n",
    "def extract_text_from_file(file_path):\n",
    "    try:\n",
    "        if file_path.endswith(\".pdf\"):\n",
    "            return extract_text(file_path)\n",
    "        elif file_path.endswith(\".txt\"):\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                return f.read()\n",
    "        else:\n",
    "            raise ValueError(\"Only PDF or TXT files are supported.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to extract text: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# --------------------------\n",
    "# 2. Clean and Split Text into Sentences\n",
    "# --------------------------\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        sentences = sent_tokenize(text)\n",
    "        return [s.strip() for s in sentences if len(s.strip()) > 30]\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Tokenization error: {e}\")\n",
    "        return []\n",
    "\n",
    "# --------------------------\n",
    "# 3. Search Sentence on Google\n",
    "# --------------------------\n",
    "def search_google_snippet(query):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    params = {\n",
    "        \"q\": f'\"{query}\"',\n",
    "        \"hl\": \"en\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(\"https://www.google.com/search\", params=params, headers=headers, timeout=10)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        snippets = soup.select(\"div.BNeawe.s3v9rd.AP7Wnd\")\n",
    "        return \" \".join([s.get_text() for s in snippets])\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Google search failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# --------------------------\n",
    "# 4. Compare Sentences Using TF-IDF Similarity\n",
    "# --------------------------\n",
    "def check_plagiarism(sentences, threshold=0.75, delay=2):\n",
    "    plagiarized = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        print(f\"🔍 Checking sentence {i+1}/{len(sentences)}...\")\n",
    "        snippet = search_google_snippet(sentence)\n",
    "        if snippet:\n",
    "            vec = TfidfVectorizer().fit_transform([sentence, snippet])\n",
    "            score = cosine_similarity(vec[0], vec[1])[0][0]\n",
    "            if score > threshold:\n",
    "                plagiarized.append((sentence, round(score, 3)))\n",
    "        time.sleep(delay)  # Prevent getting blocked by Google\n",
    "    return plagiarized\n",
    "\n",
    "# --------------------------\n",
    "# 5. Run the Plagiarism Checker\n",
    "# --------------------------\n",
    "def run_plagiarism_checker(file_path):\n",
    "    print(f\"📄 Extracting from {file_path} ...\")\n",
    "    raw_text = extract_text_from_file(file_path)\n",
    "    \n",
    "    if not raw_text:\n",
    "        print(\"⚠️ No text extracted.\")\n",
    "        return\n",
    "    \n",
    "    sentences = preprocess_text(raw_text)\n",
    "    \n",
    "    if not sentences:\n",
    "        print(\"⚠️ No valid sentences found.\")\n",
    "        return\n",
    "    \n",
    "    results = check_plagiarism(sentences)\n",
    "\n",
    "    print(\"\\n🧾 Plagiarized Sentences Found:\\n\")\n",
    "    if not results:\n",
    "        print(\"✅ No plagiarism detected.\")\n",
    "    else:\n",
    "        for sent, score in results:\n",
    "            print(f\"🔴 Score: {score} → {sent[:200]}...\")\n",
    "\n",
    "# --------------------------\n",
    "# 📌 USAGE\n",
    "# --------------------------\n",
    "your_paper_path = r\"C:\\Users\\sagni\\Downloads\\Band Selection\\paper\\IIIT Paper.pdf\"\n",
    "run_plagiarism_checker(your_paper_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cae74b4-cf0f-44c3-a76c-6bbaf37d274d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
